## ğŸ” DÃ©tection de fraude sur transactions bancaires

> SystÃ¨me de dÃ©tection des fraudes avec **74% de prÃ©cision** et **63% de rappel**, dÃ©veloppÃ© sur le dataset IEEEâ€‘CIS Fraud Detection (â‰ˆ590K transactions).

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![XGBoost](https://img.shields.io/badge/XGBoost-1.7+-green.svg)](https://xgboost.readthedocs.io/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

![Feature Importance](visualisations/feature_importance.png)

---

### Sommaire
- **Contexte et objectif**
- **RÃ©sultats clÃ©s**
- **DonnÃ©es** (tÃ©lÃ©chargement et placement)
- **PrÃ©requis & installation**
- **Reproduire lâ€™expÃ©rience**
- **Structure du dÃ©pÃ´t**
- **Pipeline de modÃ©lisation**
- **MÃ©thodologie**
- **HyperparamÃ¨tres**
- **Visualisations**
- **Limites & prochaines Ã©tapes**
- **Contact & licence**

---

## ğŸ“Œ Contexte et objectif

Dans le contexte bancaire, la dÃ©tection prÃ©coce des fraudes est cruciale. Ce projet propose un modÃ¨le de classification qui **dÃ©tecte les transactions frauduleuses** malgrÃ© un **dÃ©sÃ©quilibre de classes trÃ¨s marquÃ©** (â‰ˆ96.5% lÃ©gitimes / 3.5% fraudes).

**Objectif principal** : maximiser le rappel (dÃ©tecter un maximum de fraudes) tout en maintenant une prÃ©cision acceptable (limiter les fausses alertes).

---

## ğŸ¯ RÃ©sultats clÃ©s

| MÃ©trique | Valeur | Impact business |
|----------|--------|-----------------|
| **PrÃ©cision (fraude)** | **74%** | 7â€“8 vraies fraudes sur 10 alertes |
| **Rappel (fraude)** | **63%** | â‰ˆ 2/3 des fraudes rÃ©elles dÃ©tectÃ©es |
| **F1-Score** | **0.68** | Bon compromis prÃ©cision/rappel |
| **Fausses alertes** | **920** | âˆ’88% vs baseline Random Forest |
| **Exactitude globale** | **98%** | TrÃ¨s Ã©levÃ©e |

**Gain vs baseline** : +133% de rappel (27% â†’ 63%).

---

## ğŸ“Š DonnÃ©es

Le dataset nâ€™est pas inclus dans ce dÃ©pÃ´t. Pour reproduire :
1. TÃ©lÃ©chargez le dataset Kaggle `IEEEâ€‘CIS Fraud Detection` : `https://www.kaggle.com/c/ieee-fraud-detection`
2. Placez tous les fichiers dans le dossier `data/` Ã  la racine du projet.

---

## ğŸ§° PrÃ©requis & installation

- Python 3.8+
- Environnement virtuel recommandÃ©

```bash
python -m venv .venv
source .venv/bin/activate  # sous macOS/Linux
python -m pip install -U pip
pip install pandas numpy scikit-learn xgboost imbalanced-learn matplotlib seaborn jupyter ipykernel
```

---

## â–¶ï¸ Reproduire lâ€™expÃ©rience

1. PrÃ©parer les donnÃ©es (voir section DonnÃ©es) dans `data/`.
2. Lancer Jupyter et ouvrir les notebooks clÃ©s :
   - `Exploration_et_nettoyage_des_donnÃ©es_fraudes.ipynb`
   - `Visualisation_et_modeling.ipynb`

```bash
jupyter lab  # ou: jupyter notebook
```

---

## ğŸ—‚ï¸ Structure du dÃ©pÃ´t

```text
Fraude_bancaire/
â”œâ”€ data/
â”‚  â”œâ”€ train_transaction.csv, train_identity.csv, ...
â”œâ”€ Exploration_et_nettoyage_des_donnÃ©es_fraudes.ipynb
â”œâ”€ Visualisation_et_modeling.ipynb
â”œâ”€ df_train_encoded.pkl
â”œâ”€ df_train_reduced.pkl
â”œâ”€ label_mappings.json
â””â”€ README.md
```

---

## ğŸ› ï¸ Technologies utilisÃ©es

- **Python 3.8+** : langage principal
- **Pandas / NumPy** : manipulation des donnÃ©es
- **Scikitâ€‘learn** : preprocessing, mÃ©triques, train/validation split
- **XGBoost** : modÃ¨le retenu (surpasse la baseline Random Forest)
- **Imbalancedâ€‘learn (SMOTE)** : gestion du dÃ©sÃ©quilibre de classes
- **Matplotlib / Seaborn** : visualisations

---

## ğŸ“Š Pipeline de modÃ©lisation

1. DonnÃ©es brutes (â‰ˆ590K transactions)
2. Feature engineering & preprocessing
3. Split train/validation (80/20) avec stratification
4. RÃ©Ã©quilibrage via **SMOTE** (ratio â‰ˆ 0.5)
5. EntraÃ®nement **XGBoost** avec `scale_pos_weight="balanced"`
6. Optimisation du seuil de dÃ©cision (0.4)
7. Ã‰valuation finale : prÃ©cision 74% / rappel 63%

---

## ğŸš€ MÃ©thodologie

### 1) Exploration des donnÃ©es (EDA)
- Analyse de â‰ˆ590â€¯540 transactions, >100 features
- DÃ©sÃ©quilibre identifiÃ© : â‰ˆ3.5% de fraudes
- CorrÃ©lations : A8, A10, A7 parmi les plus prÃ©dictives

### 2) Preprocessing
- Traitement des valeurs manquantes
- SÃ©lection de variables guidÃ©e par corrÃ©lations/importance
- RÃ©duction dimensionnelle (â‰ˆ100 features conservÃ©es)

### 3) Gestion du dÃ©sÃ©quilibre
- **SMOTE** (oversampling synthÃ©tique, ratio â‰ˆ0.5)
- **PondÃ©ration de classe** : `scale_pos_weight` (XGBoost)
- **Ajustement du seuil** : 0.4 (vs 0.5 par dÃ©faut)

### 4) ModÃ©lisation
- Baseline Random Forest : rappel 71%, prÃ©cision 28%
- **XGBoost (choisi)** : rappel 63%, prÃ©cision 74% âœ…

---

## âš™ï¸ HyperparamÃ¨tres XGBoost

```python
{
    'n_estimators': 200,
    'max_depth': 8,
    'learning_rate': 0.1,
    'scale_pos_weight': 2.0,
    'eval_metric': 'aucpr'
}
```

---

## ğŸ“ˆ Visualisations

- Importance des variables (ex. `visualisations/feature_importance.png`)
- Courbe prÃ©cisionâ€“rappel et tradeâ€‘off seuil
- Matrice de confusion (validation) :

|                | PrÃ©dit lÃ©gitime | PrÃ©dit fraude |
|----------------|-----------------|---------------|
| **RÃ©el lÃ©gitime** | 113â€¯056         | 919           |
| **RÃ©el fraude**   | 1â€¯529           | 2â€¯604         |

---

## ğŸ’¡ Insights techniques

**Pourquoi XGBoost > Random Forest ?**
- Meilleure optimisation par gradient boosting
- RÃ©gularisation intÃ©grÃ©e (moins dâ€™overfitting)
- Plus robuste sur donnÃ©es dÃ©sÃ©quilibrÃ©es

**Impact du seuil de dÃ©cision**
- 0.5 (dÃ©faut) : rappel 45%, prÃ©cision 80%
- **0.4 (optimal)** : rappel 63%, prÃ©cision 74% âœ…
- 0.3 : rappel 71%, prÃ©cision 62%

---

ğŸ“ CompÃ©tences DÃ©montrÃ©es

âœ… Machine Learning : Classification supervisÃ©e, gestion du dÃ©sÃ©quilibre
âœ… Feature Engineering : SÃ©lection, crÃ©ation, analyse de corrÃ©lations
âœ… Data Preprocessing : Nettoyage, transformation, SMOTE
âœ… Model Evaluation : MÃ©triques adaptÃ©es (Precision/Recall/F1), matrices de confusion
âœ… Hyperparameter Tuning : Optimisation de seuils, comparaison de modÃ¨les
âœ… Python : Pandas, Scikit-learn, XGBoost, Matplotlib
âœ… Business Understanding : Trade-off coÃ»ts fraudes vs fausses alertes

---

## ğŸ¤ CrÃ©dits

- Dataset Kaggle `IEEEâ€‘CIS Fraud Detection` (`https://www.kaggle.com/c/ieee-fraud-detection`)

---

## ğŸ“ Contact & licence

Samia CARCHAF  â€¢  Email : `samia.carchaf@gmail.com`

LinkedIn : `https://www.linkedin.com/in/samia-carchaf-ia/`

Portfolio : `https://carchaf-portfolio.netlify.app/`

Licence : MIT